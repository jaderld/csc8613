import os
import pandas as pd
from sqlalchemy import create_engine
from feast import FeatureStore

AS_OF = "2024-01-31"
FEAST_REPO = "/repo"  # Chemin monté dans le conteneur feast

def get_engine():
    """Crée un engine SQLAlchemy pour PostgreSQL."""
    uri = (
        f"postgresql+psycopg2://{os.getenv('POSTGRES_USER','streamflow')}:"
        f"{os.getenv('POSTGRES_PASSWORD','streamflow')}@"
        f"{os.getenv('POSTGRES_HOST','postgres')}:5432/"
        f"{os.getenv('POSTGRES_DB','streamflow')}"
    )
    return create_engine(uri)

def build_entity_df(engine, as_of: str) -> pd.DataFrame:
    """Construit l'entity_df pour Feast à partir des snapshots."""
    query = """
        SELECT user_id, as_of
        FROM subscriptions_profile_snapshots
        WHERE as_of = %(as_of)s
    """
    df = pd.read_sql(query, engine, params={"as_of": as_of})
    if df.empty:
        raise RuntimeError(f"No snapshot rows found at as_of={as_of}")
    df = df.rename(columns={"as_of": "event_timestamp"})
    df["event_timestamp"] = pd.to_datetime(df["event_timestamp"])
    return df[["user_id", "event_timestamp"]]

def fetch_labels(engine, as_of: str) -> pd.DataFrame:
    """Récupère les labels de churn pour l'entity_df."""
    query = "SELECT user_id, churn_label FROM labels"
    labels = pd.read_sql(query, engine)
    if labels.empty:
        raise RuntimeError("Labels table is empty.")
    labels["event_timestamp"] = pd.to_datetime(as_of)
    return labels[["user_id", "event_timestamp", "churn_label"]]

def main():
    engine = get_engine()
    entity_df = build_entity_df(engine, AS_OF)
    labels = fetch_labels(engine, AS_OF)

    # Connexion au Feature Store Feast
    store = FeatureStore(repo_path=FEAST_REPO)

    # Liste des features à récupérer
    features = [
        "subs_profile_fv:months_active",
        "subs_profile_fv:monthly_fee",
        "subs_profile_fv:paperless_billing",
        "subs_profile_fv:plan_stream_tv",
        "subs_profile_fv:plan_stream_movies",
        "subs_profile_fv:net_service",
        "usage_agg_30d_fv:watch_hours_30d",
        "usage_agg_30d_fv:avg_session_mins_7d",
        "usage_agg_30d_fv:unique_devices_30d",
        "usage_agg_30d_fv:skips_7d",
        "usage_agg_30d_fv:rebuffer_events_7d",
        "payments_agg_90d_fv:failed_payments_90d",
        "support_agg_90d_fv:support_tickets_90d",
        "support_agg_90d_fv:ticket_avg_resolution_hrs_90d",
    ]

    # Récupération offline des features
    hf = store.get_historical_features(
        entity_df=entity_df,
        features=features,
    ).to_df()

    # Fusion avec les labels
    df = hf.merge(labels, on=["user_id", "event_timestamp"], how="inner")
    if df.empty:
        raise RuntimeError("Training set is empty after merge. Check AS_OF and labels.")

    # Sauvegarde
    os.makedirs("/data/processed", exist_ok=True)
    df.to_csv("/data/processed/training_df.csv", index=False)
    print(f"[OK] Wrote /data/processed/training_df.csv with {len(df)} rows")

if __name__ == "__main__":
    main()
